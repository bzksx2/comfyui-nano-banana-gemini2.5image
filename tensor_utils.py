"""
å¼ é‡å¤„ç†å·¥å…·å‡½æ•°
ç»Ÿä¸€å¤„ç†ComfyUIä¸­çš„å›¾åƒå¼ é‡è½¬æ¢
"""

import torch
import numpy as np
from PIL import Image
from typing import List, Union


def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    """
    å°†ComfyUIå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
    æ”¯æŒæ‰¹æ¬¡å’Œå•å¼ å›¾åƒ
    
    Args:
        tensor: è¾“å…¥å¼ é‡ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
               - (batch, height, width, channels)
               - (height, width, channels) 
               - (channels, height, width)
               - (batch, channels, height, width)
    
    Returns:
        PIL.Image: è½¬æ¢åçš„PILå›¾åƒï¼ˆå¦‚æœæ˜¯æ‰¹æ¬¡ï¼Œè¿”å›ç¬¬ä¸€å¼ ï¼‰
    """
    
    # å¤„ç†æ‰¹æ¬¡å›¾åƒï¼šå¦‚æœæ˜¯4ç»´å¼ é‡ï¼Œå–ç¬¬ä¸€å¼ å›¾åƒ
    if len(tensor.shape) == 4:
        tensor = tensor[0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
    
    # å¤„ç†3ç»´å¼ é‡
    if len(tensor.shape) == 3:
        # å¦‚æœæ˜¯ (channels, height, width) æ ¼å¼ï¼Œè½¬æ¢ä¸º (height, width, channels)
        if tensor.shape[0] == 3 or tensor.shape[0] == 1:
            tensor = tensor.permute(1, 2, 0)
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®å¹¶è½¬æ¢ä¸ºPILå›¾åƒ
    if tensor.dtype != torch.uint8:
        tensor = (tensor * 255).clamp(0, 255).byte()
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    numpy_array = tensor.cpu().numpy()
    
    # å¤„ç†å•é€šé“å›¾åƒ
    if len(numpy_array.shape) == 3 and numpy_array.shape[-1] == 1:
        numpy_array = numpy_array.squeeze(-1)
        return Image.fromarray(numpy_array, mode='L')
    
    # å¤„ç†ç°åº¦å›¾åƒ
    if len(numpy_array.shape) == 2:
        return Image.fromarray(numpy_array, mode='L')
    
    # å¤„ç†RGBå›¾åƒ
    return Image.fromarray(numpy_array)


def batch_tensor_to_pil_list(tensor: torch.Tensor) -> List[Image.Image]:
    """
    å°†æ‰¹æ¬¡å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨
    
    Args:
        tensor: æ‰¹æ¬¡å¼ é‡ (batch, height, width, channels) æˆ– (batch, channels, height, width)
    
    Returns:
        List[PIL.Image]: PILå›¾åƒåˆ—è¡¨
    """
    images = []
    
    # å¤„ç†4ç»´å¼ é‡ (batch, height, width, channels) æˆ– (batch, channels, height, width)
    if len(tensor.shape) == 4:
        batch_size = tensor.shape[0]
        print(f"ğŸ“Š å¤„ç†æ‰¹æ¬¡å¼ é‡ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        for i in range(batch_size):
            single_tensor = tensor[i]
            
            # å¤„ç†é€šé“ç»´åº¦
            if len(single_tensor.shape) == 3:
                if single_tensor.shape[0] == 3 or single_tensor.shape[0] == 1:
                    single_tensor = single_tensor.permute(1, 2, 0)
            
            # è½¬æ¢æ•°æ®ç±»å‹
            if single_tensor.dtype != torch.uint8:
                single_tensor = (single_tensor * 255).clamp(0, 255).byte()
            
            numpy_array = single_tensor.cpu().numpy()
            
            # å¤„ç†å•é€šé“å›¾åƒ
            if len(numpy_array.shape) == 3 and numpy_array.shape[-1] == 1:
                numpy_array = numpy_array.squeeze(-1)
                images.append(Image.fromarray(numpy_array, mode='L'))
            elif len(numpy_array.shape) == 2:
                images.append(Image.fromarray(numpy_array, mode='L'))
            else:
                images.append(Image.fromarray(numpy_array))
    
    # å¤„ç†3ç»´å¼ é‡ï¼ˆå•å¼ å›¾åƒï¼‰
    elif len(tensor.shape) == 3:
        images.append(tensor_to_pil(tensor))
    
    return images


def pil_to_tensor(image: Image.Image) -> torch.Tensor:
    """
    å°†PILå›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼
    
    Args:
        image: PILå›¾åƒ
    
    Returns:
        torch.Tensor: ComfyUIæ ¼å¼çš„å¼ é‡ (1, height, width, channels)
    """
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    image_array = np.array(image).astype(np.float32) / 255.0
    tensor = torch.from_numpy(image_array).unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    return tensor


def get_tensor_info(tensor: torch.Tensor) -> str:
    """
    è·å–å¼ é‡çš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
    
    Args:
        tensor: è¾“å…¥å¼ é‡
    
    Returns:
        str: å¼ é‡ä¿¡æ¯å­—ç¬¦ä¸²
    """
    info = f"å½¢çŠ¶: {tensor.shape}, æ•°æ®ç±»å‹: {tensor.dtype}"
    
    if len(tensor.shape) == 4:
        batch, height, width, channels = tensor.shape
        info += f", æ‰¹æ¬¡: {batch}, å°ºå¯¸: {height}x{width}, é€šé“: {channels}"
    elif len(tensor.shape) == 3:
        if tensor.shape[0] <= 4:  # å¯èƒ½æ˜¯é€šé“åœ¨å‰
            channels, height, width = tensor.shape
            info += f", é€šé“: {channels}, å°ºå¯¸: {height}x{width} (CHWæ ¼å¼)"
        else:  # å¯èƒ½æ˜¯é€šé“åœ¨å
            height, width, channels = tensor.shape
            info += f", å°ºå¯¸: {height}x{width}, é€šé“: {channels} (HWCæ ¼å¼)"
    
    return info


def normalize_tensor_format(tensor: torch.Tensor) -> torch.Tensor:
    """
    æ ‡å‡†åŒ–å¼ é‡æ ¼å¼ä¸ºComfyUIæœŸæœ›çš„æ ¼å¼
    
    Args:
        tensor: è¾“å…¥å¼ é‡
    
    Returns:
        torch.Tensor: æ ‡å‡†åŒ–åçš„å¼ é‡ (batch, height, width, channels)
    """
    
    # å¦‚æœæ˜¯3ç»´å¼ é‡ï¼Œæ·»åŠ æ‰¹æ¬¡ç»´åº¦
    if len(tensor.shape) == 3:
        # æ£€æŸ¥æ˜¯å¦æ˜¯CHWæ ¼å¼
        if tensor.shape[0] <= 4:  # é€šé“æ•°é€šå¸¸ä¸è¶…è¿‡4
            tensor = tensor.permute(1, 2, 0)  # CHW -> HWC
        tensor = tensor.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    
    # å¦‚æœæ˜¯4ç»´å¼ é‡ä½†é€šé“åœ¨ç¬¬äºŒä¸ªä½ç½® (batch, channels, height, width)
    elif len(tensor.shape) == 4 and tensor.shape[1] <= 4:
        tensor = tensor.permute(0, 2, 3, 1)  # BCHW -> BHWC
    
    return tensor