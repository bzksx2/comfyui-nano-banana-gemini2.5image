"""\nOpenRouter å›¾åƒç¼–è¾‘èŠ‚ç‚¹\næ”¯æŒå•å›¾å’Œå¤šå›¾è¾“å…¥ï¼Œè‡ªåŠ¨å¤„ç†æ‰¹æ¬¡æ•°æ®\n"""

import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import json
import time
import random
from typing import Optional, Tuple, Dict, Any, List
from openai import OpenAI
import logging
import os, sys
sys.path.insert(0, os.path.dirname(__file__))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

try:
    from tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    from .utils import (
        image_to_base64, base64_to_image,
        validate_api_key, format_error_message, resize_image_for_api
    )
    from .config import DEFAULT_CONFIG
except ImportError:
    logger.error("load tensor utils error")
    from tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    # Fallback utility functions - å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨å†…ç½®ç‰ˆæœ¬
    pass
    
    def image_to_base64(image, format='JPEG'):
        buffer = io.BytesIO()
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
            image = background
        image.save(buffer, format=format, quality=95)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def validate_api_key(api_key):
        return api_key and len(api_key.strip()) > 10
    
    def format_error_message(error):
        return str(error)
    
    DEFAULT_CONFIG = {"timeout": 120, "max_retries": 3}


def smart_retry_delay(attempt, error_code=None):
    """æ™ºèƒ½é‡è¯•å»¶è¿Ÿ"""
    base_delay = 2 ** attempt
    
    if error_code == 429:
        rate_limit_delay = 60 + random.uniform(10, 30)
        return max(base_delay, rate_limit_delay)
    elif error_code in [500, 502, 503, 504]:
        return base_delay + random.uniform(1, 5)
    else:
        return base_delay


class OpenRouterImageEdit:
    """OpenRouter å›¾åƒç¼–è¾‘èŠ‚ç‚¹ - æ”¯æŒå•å›¾å’Œå¤šå›¾è¾“å…¥"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "base_url": ("STRING", {"default": "https://openrouter.ai/api/v1", "multiline": False}),
                "site_url": ("STRING", {"default": "https://your-site.com", "multiline": False}),
                "site_name": ("STRING", {"default": "Your Site Name", "multiline": False}),
                "prompt": ("STRING", {"default": "Describe these images and edit them", "multiline": True}),
                "model": ([
                    "google/gemini-2.5-flash-image-preview:free",
                    "google/gemini-2.5-flash-image-preview"
                ], {"default": "google/gemini-2.5-flash-image-preview:free"}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_tokens": ("INT", {"default": 8192, "min": 1, "max": 32768}),
                "process_mode": ([
                    "first_image_only",
                    "all_images_combined",
                    "each_image_separately"
                ], {"default": "each_image_separately"}),
            },
            "optional": {
                "images": ("IMAGE",),  # æ”¯æŒæ‰¹æ¬¡å›¾åƒ
                "image_urls": ("STRING", {"default": "", "multiline": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("edited_image",)
    FUNCTION = "edit_images"
    CATEGORY = "OpenRouter"
    
    def edit_images(self, api_key: str, base_url: str, site_url: str, site_name: str,
                    prompt: str, model: str, temperature: float, top_p: float,
                    max_tokens: int, process_mode: str, images: Optional[torch.Tensor] = None,
                    image_urls: str = "") -> torch.Tensor:
        """æ‰¹æ¬¡å¤„ç†å›¾åƒç¼–è¾‘"""
        
        # éªŒè¯APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("API Keyæ ¼å¼æ— æ•ˆæˆ–ä¸ºç©º")
        
        # éªŒè¯æç¤ºè¯
        if not prompt.strip():
            raise ValueError("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯è¾“å…¥ï¼šè‡³å°‘éœ€è¦ä¸€ä¸ªå›¾åƒæ¥æº
        if images is None and not image_urls.strip():
            raise ValueError("å¿…é¡»æä¾›è‡³å°‘ä¸€ä¸ªå›¾åƒæ¥æºï¼šimages æˆ– image_urls")
        
        # å¦‚æœæä¾›äº†å›¾åƒå¼ é‡ï¼Œè½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨
        pil_images = []
        if images is not None:
            print(f"ğŸ“Š è¾“å…¥å¼ é‡ä¿¡æ¯: {get_tensor_info(images)}")
            pil_images = batch_tensor_to_pil_list(images)
            print(f"ğŸ–¼ï¸ è½¬æ¢å¾—åˆ° {len(pil_images)} å¼ å›¾åƒ")
        
        # è§£æimage_urls
        url_list = [url.strip() for url in image_urls.split('\n') if url.strip()] if image_urls else []
        if url_list:
            print(f"ğŸ”— æä¾›äº† {len(url_list)} ä¸ªå›¾åƒURL")
        
        # å¦‚æœåªæœ‰URLï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„PILå›¾åƒä½œä¸ºå ä½ç¬¦
        if not pil_images and url_list:
            pil_images = [Image.new('RGB', (1, 1), (0, 0, 0)) for _ in url_list]
        
        print(f"ğŸ”§ å¤„ç†æ¨¡å¼: {process_mode}")
        
        if process_mode == "first_image_only":
            # åªå¤„ç†ç¬¬ä¸€å¼ å›¾åƒ
            return self._process_single_image(
                api_key, base_url, site_url, site_name, pil_images[0],
                prompt, model, temperature, top_p, max_tokens,
                url_list[0] if url_list else ""
            )[0]
        
        elif process_mode == "all_images_combined":
            # å°†æ‰€æœ‰å›¾åƒåˆå¹¶å‘é€
            return self._process_combined_images(
                api_key, base_url, site_url, site_name, pil_images,
                prompt, model, temperature, top_p, max_tokens,
                image_urls
            )[0]
        
        elif process_mode == "each_image_separately":
            # åˆ†åˆ«å¤„ç†æ¯å¼ å›¾åƒï¼Œè¿”å›æ‰€æœ‰ç»“æœ
            return self._process_images_separately(
                api_key, base_url, site_url, site_name, pil_images,
                prompt, model, temperature, top_p, max_tokens,
                image_urls
            )[0]

    def _process_single_image(self, api_key: str, base_url: str, site_url: str, site_name: str,
                             pil_image: Image.Image, prompt: str, model: str,
                             temperature: float, top_p: float,
                             max_tokens: int, image_url: str = "") -> Tuple[torch.Tensor, str]:
        """å¤„ç†å•å¼ å›¾åƒ"""
        
        # æ ¹æ®æ˜¯å¦æä¾›URLå†³å®šä½¿ç”¨base64è¿˜æ˜¯ç›´æ¥URL
        if image_url and image_url.strip():
            image_data = {"url": image_url.strip()}
        else:
            # è½¬æ¢ä¸ºbase64
            image_base64 = image_to_base64(pil_image, format='JPEG')
            image_data = {"url": f"data:image/jpeg;base64,{image_base64}"}
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            base_url=base_url,
            api_key=api_key.strip()
        )
        
        try:
            # åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚
            completion = client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": site_url,
                    "X-Title": site_name,
                },
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt.strip()
                            },
                            {
                                "type": "image_url",
                                "image_url": image_data
                            }
                        ]
                    }
                ],
                temperature=temperature,
                top_p=top_p
                # max_tokens=max_tokens
            )

            choice = completion["choices"][0]
            message = choice["message"]

            if "images" in message and message["images"]:
                image_url = message["images"][0]["image_url"]["url"]
                if image_url.startswith("data:image"):
                    base64_str = image_url.split(",", 1)[1]
                    image_bytes = base64.b64decode(base64_str)
                    edited_image = Image.open(io.BytesIO(image_bytes))
                    print("âœ… æˆåŠŸæå–ç¼–è¾‘åçš„å›¾ç‰‡")
                else:
                    raise ValueError("è¿”å›çš„ä¸æ˜¯ base64 å›¾åƒæ•°æ®")
            else:
                raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")

            image_tensor = pil_to_tensor(edited_image)
            print("âœ… å›¾ç‰‡å¤„ç†å®Œæˆ")
            return (image_tensor, '')
            
        except Exception as e:
            error_msg = format_error_message(e)
            print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
            raise ValueError(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {error_msg}")
    
    def _process_combined_images(self, api_key: str, base_url: str, site_url: str, site_name: str,
                                pil_images: List[Image.Image], prompt: str, model: str,
                                temperature: float, top_p: float,
                                max_tokens: int, image_urls: str = "") -> Tuple[torch.Tensor, str]:
        """å¤„ç†å¤šå¼ å›¾åƒï¼ˆåˆå¹¶å‘é€ï¼‰"""
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            base_url=base_url,
            api_key=api_key.strip()
        )
        try:
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = [
                {
                    "type": "text",
                    "text": prompt.strip()
                }
            ]
            
            # è§£æimage_urlsï¼ˆå¦‚æœæä¾›ï¼‰
            url_list = [url.strip() for url in image_urls.split('\n') if url.strip()] if image_urls else []
            
            # æ·»åŠ æ‰€æœ‰å›¾åƒ
            for i, pil_image in enumerate(pil_images):
                if i < len(url_list):
                    # ä½¿ç”¨æä¾›çš„URL
                    image_data = {"url": url_list[i]}
                else:
                    # ä½¿ç”¨base64
                    image_base64 = image_to_base64(pil_image, format='JPEG')
                    image_data = {"url": f"data:image/jpeg;base64,{image_base64}"}
                
                content.append({
                    "type": "image_url",
                    "image_url": image_data
                })
                print(f"ğŸ“ æ·»åŠ ç¬¬ {i+1} å¼ å›¾åƒåˆ°è¯·æ±‚ä¸­")
            
                # åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚
                completion = client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": site_url,
                        "X-Title": site_name,
                    },
                    model=model,
                    messages=[{
                        "role": "user",
                        "content": content
                    }],
                    temperature=temperature,
                    top_p=top_p,
                    max_tokens=max_tokens
                )
                
                choice = completion["choices"][0]
                message = choice["message"]

                if "images" in message and message["images"]:
                    image_url = message["images"][0]["image_url"]["url"]
                    if image_url.startswith("data:image"):
                        base64_str = image_url.split(",", 1)[1]
                        image_bytes = base64.b64decode(base64_str)
                        edited_image = Image.open(io.BytesIO(image_bytes))
                        print("âœ… æˆåŠŸæå–ç¼–è¾‘åçš„å›¾ç‰‡")
                    else:
                        raise ValueError("è¿”å›çš„ä¸æ˜¯ base64 å›¾åƒæ•°æ®")
                else:
                    raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")

                image_tensor = pil_to_tensor(edited_image)
                
                print("âœ… å›¾ç‰‡å¤„ç†å®Œæˆ")
                return (image_tensor, "")
            
        except Exception as e:
            error_msg = format_error_message(e)
            print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
            raise ValueError(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {error_msg}")
    
    def _process_images_separately(self, api_key: str, base_url: str, site_url: str, site_name: str,
                                  pil_images: List[Image.Image], prompt: str, model: str,
                                  temperature: float, top_p: float,
                                  max_tokens: int, image_urls: str = "") -> Tuple[torch.Tensor, str]:
        """åˆ†åˆ«å¤„ç†æ¯å¼ å›¾åƒ"""
        
        all_edited_images = []
        all_responses = []
        
        # è§£æimage_urlsï¼ˆå¦‚æœæä¾›ï¼‰
        url_list = [url.strip() for url in image_urls.split('\n') if url.strip()] if image_urls else []
        
        for i, pil_image in enumerate(pil_images):
            print(f"ğŸ”„ å¤„ç†ç¬¬ {i+1}/{len(pil_images)} å¼ å›¾åƒ")
            
            # ä¸ºæ¯å¼ å›¾åƒæ·»åŠ åºå·åˆ°æç¤ºè¯ä¸­
            numbered_prompt = f"Image {i+1}/{len(pil_images)}: {prompt}"
            
            # å¤„ç†å•å¼ å›¾åƒ
            image_url = url_list[i] if i < len(url_list) else ""
            edited_image, response = self._process_single_image(
                api_key, base_url, site_url, site_name, pil_image, numbered_prompt,
                model, temperature, top_p, max_tokens, image_url
            )
            
            all_edited_images.append(edited_image)
            all_responses.append(f"Image {i+1}/{len(pil_images)}:\n{response}\n")
        
        # åˆå¹¶æ‰€æœ‰ç¼–è¾‘åçš„å›¾åƒå’Œå“åº”
        if len(all_edited_images) > 1:
            combined_images = torch.cat(all_edited_images, dim=0)
        else:
            combined_images = all_edited_images[0]
        
        combined_response = "\n---\n".join(all_responses)
        
        return combined_images


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "OpenRouterImageEdit": OpenRouterImageEdit,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "OpenRouterImageEdit": "OpenRouter å›¾åƒç¼–è¾‘",
}